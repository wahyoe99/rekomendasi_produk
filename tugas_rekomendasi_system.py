# -*- coding: utf-8 -*-
"""Tugas_Rekomendasi_system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yvj0Vp7vPEcHDmV4L9-coHz1n3D3c2rO

# Rekomendasi Product E-commerce
## 1. Domain Proyek
*E-commerce* adalah salah satu inovasi di era modern ini yang memiliki fungsi untuk membantu konsumen membeli barang-barang yang mereka butuhkan dengan mudah melalui gawai mereka. Selain membantu konsumen, *e-commerce* juga membantu banyak penjual dalam menjual barangnya dengan lebih mudah. Dengan *e-commerce*, penjual dapat menjual barang tidak hanya terbatas kepada konsumen di daerahnya saja, tetapi penjual dapat menjual produknya ke konsumen di seluruh dunia.

Saat ini telah banyak sekali barang-barang yang dijual di *e-commerce*. Tak jarang barang-barang tersebut terdapat barang yang dijual oleh seorang penipu yang dapat merugikan konsumen. Oleh karena itu, pemilik *platform e-commerce* perlu memberikan rasa aman dan rasa nyaman kepada para konsumen dengan memfilter barang-barang yang direkomendasikan kepada user.

Selain itu, pemilik e-commerce juga perlu sebuah sistem rekomendasi yang dapat merekomendasikan barang yang sesuai dengan yang pembeli butuhkan atau pembeli inginkan. Hal ini bertujuan untuk memberikan kemudahan kepada pengguna, dan tentunya meningkatkan *trafic* dan transaksi di platform *e-commerce* tersebut. Sebagai pembeli, sistem rekomendasi dapat memberikan kemudahan bagi pembeli untuk menemukan produk yang sesuai dengan yang kita inginkan. Sebagai penjual, bisa dibilang sistem rekomendasi ini dapat mengiklankan produknya secara tepat kepada orang-orang yang benar-benar membutuhkan atau menginginkan produk tersebut.

Terdapat dua pendekatan yang umum digunakan untuk membuat sistem rekomendasi, yaitu *content-based filtering* dan *collaborative filtering*. *Content-based filtering* sangat berguna untuk diterapkan pada fitur _search engine e-commerce_. Karena *content-based filtering* ini mengandalkan _keyword_ untuk bisa memperoleh rekomendasi produk yang relevan. *Collaborative filtering* sangat berguna untuk diterapkan kepada setiap pengguna sehingga pengguna bisa dengan cepat menemukan produk yang mungkin relevan dan sedang diinginkan oleh pembeli tanpa perlu menggunakan fitur _search engine_.

## 2. Business Understanding
### 2.1. Problem Statements
Dari kondisi yang telah dijelaskan di atas, akan dibuat sebuah sistem rekomendasi untuk menjawab permasalahan berikut:
* Bagaimana cara memberikan rekomendasi produk yang relevan kepada pengguna berdasarkan preferensi dan perilaku mereka?
* Bagaimana sistem rekomendasi dapat membantu meningkatkan pengalaman belanja pengguna dan mendorong penjualan?
* Bagaimana kita dapat memanfaatkan informasi dari pengguna, produk, dan riwayat pembelian untuk menghasilkan rekomendasi yang personal dan akurat?

### 2.2. Goals
* Membuat sistem rekomendasi yang bisa memberikan rekomendasi produk yang relevan dengan preferensi pengguna.
* Mengetahui kemampuan sistem rekomendasi dalam memberikan rekomendasi produk kepada pengguna.
* Mengoptimalkan pemanfaatan data pelanggan dan produk yang ada dalam platform *e-commerce* untuk membuat sistem rekomendasi lebih akurat dan presisi.

### 2.3. Solution Approach
Untuk mencapai tujuan di atas, akan digunakan dua pendekatan dalam sistem rekomendasi kami, yaitu:
1. *Content-Based Filtering*, yang dapat memberikan rekomendasi produk yang memiliki kesamaan konden dengan produk yang disukai atau dicari oleh konsumen.
2. *Collaborative Filtering*, yang dapat memberikan rekomendasi berdasarkan preferensi konsumen atau pelanggan yang mirip.

## 3. Data Understanding
Data yang akan digunakan untuk project ini adalah data dari Kaggle yang berisi merupakan data informasi *custumer*, produk, dan *review* dari salah satu platform *e-commerce* bernama *Olist*. Data dapat diunduh melalui [tautan berikut](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce). Data ini telah diproses oleh *publisher* sehingga data ini tidak mengambil privasi konsumen maupun penjual dari *e-commerce* tersebut.

Dataset ini terdiri dari 9 skema dataset, diantaranya:
1. olist_order_customers_dataset.csv
2. olist_geolocation_dataset.csv
3. olist_order_items_dataset.csv
4. olist_order_payments_dataset.csv
5. olist_order_reviews_dataset.csv
6. olist_orders_dataset.csv
7. olist_products_dataset.csv
8. olist_seller_dataset.csv
9. product_category_name_translation.csv

# Packages Preparation
"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

"""## Import dari Kaggle"""

#copy dataset dari kaggle https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce
!kaggle datasets download -d olistbr/brazilian-ecommerce

#extract dataset yang sudah di copy diatas ke dalam googlecolab dan folder content
import zipfile
local_zip = '/content/brazilian-ecommerce.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

"""## Dataframe

Terdapat 9 skema dataset yang tersedia. Namun pada project ini hanya akan digunakan 6 skema dataset, yaitu:
1. olist_order_customers_dataset.csv
2. olist_order_items_dataset.csv
3. olist_order_reviews_dataset.csv
4. olist_orders_dataset.csv
5. olist_products_dataset.csv
6. olist_seller_dataset.csv
7. product_category_name_translation.csv
"""

raw_cust = pd.read_csv('/content/olist_customers_dataset.csv')
# raw_geoloc = pd.read_csv('/content/olist_geolocation_dataset.csv')
raw_order_items = pd.read_csv('/content/olist_order_items_dataset.csv')
# raw_order_payments = pd.read_csv('/content/olist_order_payments_dataset.csv')
raw_order_reviews = pd.read_csv('/content/olist_order_reviews_dataset.csv')
raw_orders = pd.read_csv('/content/olist_orders_dataset.csv')
raw_products = pd.read_csv('/content/olist_products_dataset.csv')
raw_sellers = pd.read_csv('/content/olist_sellers_dataset.csv')
product_cats_translation = pd.read_csv('/content/product_category_name_translation.csv')

print('Dimensi data raw_cust:', raw_cust.shape,'\n\t', list(raw_cust.columns))
# print('\nDimensi data raw_geoloc:', raw_geoloc.shape, '\n\t', list(raw_geoloc.columns))
print('\nDimensi data raw_order_items:', raw_order_items.shape,'\n\t', list(raw_order_items.columns))
# print('\nDimensi data raw_order_payments:', raw_order_payments.shape, '\n\t', list(raw_order_payments.columns))
print('\nDimensi data raw_order_reviews:', raw_order_reviews.shape,'\n\t', list(raw_order_reviews.columns))
print('\nDimensi data raw_orders:', raw_orders.shape, '\n\t', list(raw_orders.columns))
print('\nDimensi data raw_products:', raw_products.shape,'\n\t', list(raw_products.columns))
print('\nDimensi data raw_sellers:', raw_sellers.shape, '\n\t', list(raw_sellers.columns))
print('\nDimensi data product_cats_translation:', product_cats_translation.shape,'\n\t', list(product_cats_translation.columns))

"""# Univariate EDA

## Order customers dataset

Pertama akan dieksplorasi data customers dengan mengecek apakah ada missing value dan duplicated data.
"""

raw_cust.isna().sum()

raw_cust.duplicated().sum()

"""Data customers tidak ada data yang kosong dan tidak ada data duplikat.

Untuk menyederhanakan data, informasi lokasi yang digunakan hanyalah kota customers (_customer_city_)
"""

raw_cust.drop(['customer_zip_code_prefix', 'customer_state'], axis=1,
              inplace=True)
raw_cust.info()

"""Selanjutnya akan dilihat nilai unik tiap kolom."""

print('Jumlah customers: ', len(raw_cust.customer_id.unique()))
print('Jumlah customers unik: ', len(raw_cust.customer_unique_id.unique()))
print('Jumlah kota unik:', len(raw_cust.customer_city.unique()))

raw_cust.customer_city.value_counts()[:10].sort_values(ascending=True).plot(kind='barh',
                                                                            title='Jumlah pembeli tiap kota')

"""## Order items dataset

Seperti biasa, cek dulu kondisi data
"""

raw_order_items.isna().sum()

raw_order_items.duplicated().sum()

"""Kolom *shipping_limit_date* akan dihapus karena tidak akan digunakan."""

raw_order_items.drop(['shipping_limit_date'], axis=1,
                     inplace=True)
raw_order_items.info()

"""Selanjutnya akan dilihat nilai unik tiap kolom."""

print('Jumlah order_id: ', len(raw_order_items.order_id.unique()))
print('Jumlah order_item_id: ', len(raw_order_items.order_item_id.unique()))
print('Jumlah product_id: ', len(raw_order_items.product_id.unique()))
print('Jumlah seller_id: ', len(raw_order_items.seller_id.unique()))
print('Jumlah price: ', len(raw_order_items.price.unique()))
print('Jumlah freight_value: ', len(raw_order_items.freight_value.unique()))

"""Selanjutnya akan dilihat statistik deskriptif dari kolom dengan tipe data numerik, yaitu total harga"""

raw_order_items.describe()

"""Eksplor sedikit lebih dalam variabel *order_item_id*"""

raw_order_items.order_item_id.unique()

raw_order_items[raw_order_items.order_item_id == 5]

raw_order_items[raw_order_items.order_id == '02a065131a2d2b72b45e2c63135606ad']

"""Kolom *order_item_id* akan dihapus karena tidak akan digunakan."""

raw_order_items.drop('order_item_id', axis=1, inplace=True)
raw_order_items.info()

"""## Order reviews dataset"""

raw_order_reviews.isna().sum()

raw_order_reviews.duplicated().sum()

"""Terdapat review yang tidak menggunakan pesan atau komentar, hanya berupa skor. Namun project ini hanya akan mengambil skor review saja tanpa menggunakan pesan atau komentar reviewnya, maka kolom *review_comment_title* dan *review_comment_message* akan dihapus."""

raw_order_reviews.drop(['review_comment_title', 'review_comment_message'],
                       axis=1, inplace=True)
raw_order_reviews.head()

"""Selanjutnya kolom *review_creation_date* dan *review_answer_timestamp* akan dihapus."""

raw_order_reviews.drop(['review_creation_date', 'review_answer_timestamp'],
                       axis=1, inplace=True)

raw_order_reviews.info()

raw_order_reviews.describe()

"""## Orders dataset"""

raw_orders.duplicated().sum()

raw_orders.isna().sum()

raw_orders.head()

raw_orders.order_status.value_counts().sort_values(ascending=True).plot(kind='barh', title='order_status')

"""Hanya akan digunakan order yang statusnya delivered."""

raw_orders = raw_orders[raw_orders.order_status == 'delivered']
raw_orders.isna().sum()

"""Karena nilai yang kosong hanya 14 baris, maka nilai yang kosong ini akan disingkirkan."""

raw_orders.dropna(inplace=True)

"""Kolom *order_purchase_timestamp*, *order_approved_at* akan digunakan untuk membuat fitur baru lama respon penjual terhadap sebuah order

Sedangkan kolom *order_delivered_carrier_date*, *order_delivered_customer_date*, dan *order_estimated_delivery_date* akan dihapus. Begitu pula kolom *order_status* akan dihapus.
"""

raw_orders.drop(['order_status',
                 'order_delivered_carrier_date',
                 'order_delivered_customer_date',
                 'order_estimated_delivery_date'],
                axis=1, inplace=True)

raw_orders.info()

raw_orders['order_purchase_timestamp'] = pd.to_datetime(raw_orders.order_purchase_timestamp,
                                                        format="%Y-%m-%d %H:%M:%S")
raw_orders['order_approved_at'] = pd.to_datetime(raw_orders.order_approved_at,
                                                 format="%Y-%m-%d %H:%M:%S")

raw_orders['respons_time_order'] = raw_orders.order_approved_at - raw_orders.order_purchase_timestamp

raw_orders.drop(['order_purchase_timestamp', 'order_approved_at'], axis=1, inplace=True)

raw_orders.info()

"""## Seller dataset"""

raw_sellers.duplicated().sum()

raw_sellers.isna().sum()

"""Karena informasi lokasi customer yang digunakan hanya informasi kota, maka informasi lokasi seller juga hanya akan menggunakan informasi kota."""

raw_sellers.drop(['seller_zip_code_prefix', 'seller_state'], axis=1, inplace=True)
raw_sellers.info()

print('Jumlah seller unik:', len(raw_sellers.seller_id.unique()))
print('Jumlah kota seller unik:', len(raw_sellers.seller_city.unique()))

raw_sellers.seller_city.value_counts()[:10].sort_values(ascending=True).plot(kind='barh',
                                                                             title='Top 10 kota dengan penjual terbanyak')

"""## Products dataset"""

raw_products.duplicated().sum()

raw_products.isna().sum()

raw_products.shape

"""Terdapat beberapa produk yang nama kategori, nama produk, deskripsi, dan fotonya hilang. Namun karena jumlahnya sedikit, akan dihapus saja.

Sebelum itu, akan dihapus dulu kolom *product_name_length* dan *product_description_length*.
"""

raw_products.drop(['product_name_lenght', 'product_description_lenght'],
                  axis=1, inplace=True)

raw_products.dropna(inplace=True)

raw_products.isna().sum()

raw_products.product_category_name.unique()

"""Karena kategori produk masih dalam Bahasa Portugis, agar kita lebih mudah membacanya, akan diubah menjadi Bahasa Inggris."""

dict_product = dict(zip(product_cats_translation.product_category_name,
                        product_cats_translation.product_category_name_english))

raw_products.replace({'product_category_name': dict_product}, inplace=True)
raw_products.head()

raw_products.product_category_name.value_counts()[:10].sort_values(ascending=True).plot(kind='barh',
                                                                                        title='Top 10 kategori produk')

"""# Data Preprocessing

1. customers
  * customer_id
  * customer_unique_id
  * customer_city
2. order items
  * order_id
  * product_id
  * seller_id
  * price
  * freight_value
3. order_reviews
  * review_id
  * order_id
  * review_score
  * respons_time_review
4. orders
  * order_id
  * customer_id
  * respons_time_order
5. sellers
  * seller_id
  * seller_city
6. product_id
  * product_id
  * product_category_name
  * product_photos_qty
  * product_weight_g
  * product_length_cm
  * product_height_cm
  * product_width_cm

Karena dataset tidak menyediakan nama produk dan nama seller yang asli, maka akan dibuat nama produk dan seller buatan secara random untuk mempermudah membaca produk

## Membuat nama product buatan
"""

product_all = np.concatenate((
    raw_order_items.product_id.unique(),
    raw_products.product_id.unique()
))

product_all = np.sort(np.unique(product_all))

product_name = ('product_' + str(i) for i in range(len(product_all)))

product_name_dict = dict(zip(product_all, product_name))

print('Jumlah total produk unik:', len(product_name_dict))

raw_order_items.replace({'product_id': product_name_dict}, inplace=True)
raw_products.replace({'product_id': product_name_dict}, inplace=True)
raw_order_items.head()

"""## Membuat nama seller buatan"""

seller_all = np.concatenate((
    raw_order_items.seller_id.unique(),
    raw_sellers.seller_id.unique()
))

seller_all = np.sort(np.unique(seller_all))

seller_name = {'seller_' + str(i) for i in range(len(seller_all))}

seller_name_dict = dict(zip(seller_all, seller_name))

print('Jumlah total seller unik:', len(seller_name_dict))

raw_order_items.replace({'seller_id': seller_name_dict}, inplace=True)
raw_sellers.replace({'seller_id': seller_name_dict}, inplace=True)
raw_sellers.head()

"""## Harga product

Terkadang harga produk berubah-ubah. Sehingga akan diambil harga rata-ratanya saja.
"""

price_products = raw_order_items[['product_id', 'price']]

price_products = price_products.groupby('product_id').mean().reset_index()

products = pd.merge(raw_products, price_products, on='product_id', how='left')
products.sample(3)

products.isna().sum()

"""## Review dan jumlah product terjual"""

rating_order = pd.merge(raw_order_items, raw_order_reviews[['order_id', 'review_score']],
                        on='order_id', how='left')[['product_id', 'review_score']]

rating_products = rating_order.groupby('product_id').mean().round(1).reset_index()
sold_products = rating_order.groupby('product_id').count().reset_index()

rating_sold = pd.merge(rating_products, sold_products, on='product_id',
                       how='left')

rating_sold.rename(columns={'review_score_x': 'review_score',
                            'review_score_y': 'sold'},
                   inplace=True)

products = pd.merge(products, rating_sold, on='product_id', how='left')
products.head()

products.isna().sum()

"""Terdapat 157 produk yang belum memiliki review walau sudah terjual.

## Masukan nama seller ke products
"""

seller_products = raw_order_items.drop_duplicates(['product_id'])[['product_id',
                                                                   'seller_id']]

products = pd.merge(products, seller_products, on='product_id', how='left')
products.head()

products.isna().sum()

"""## Masukan respons time ke seller"""

respons_time_order = pd.merge(raw_order_items, raw_orders[['order_id',
                                                           'respons_time_order']],
                              on='order_id', how='left')[['seller_id', 'respons_time_order']]

respons_time_order = respons_time_order.groupby('seller_id').mean().reset_index()

products = pd.merge(products, respons_time_order, on='seller_id', how='left')
products.head()

"""# Data Preparation"""

products.isna().sum()

"""Terdapat beberapa produk yang memiliki nilai review yang hilang dan respons_time_order yang hilang juga.

Untuk review score, akan diganti nilai yang hilang tersebut dengan 0.
Begitu pula untuk respons time akan diganti dengan 0.
"""

products['review_score'] = products.review_score.fillna(0)
products['respons_time_order'] = products.respons_time_order.fillna(pd.Timedelta(0))
products.info()

print('jumlah product:', len(products.product_id.unique()))
print('jumlah kategori product:', len(products.product_category_name.unique()))
print('ada berapa product id yang duplikat?', products.duplicated('product_id').sum())
print('ada berapa seller id yang duplikat?', products.duplicated('seller_id').sum())

products_new = products[['product_id', 'product_category_name', 'seller_id',
                         'price', 'review_score', 'sold']]

products_new.head()

"""# Model Development dengan Content Based Filtering"""

data = products_new
data.sample(5)

"""## TF-IDF Vectorizer"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada nama kategori produk
tf.fit(data['product_category_name'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data['product_category_name'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan jenis masakan
# Baris diisi dengan nama resto

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data.product_id
).sample(22, axis=1).sample(10, axis=0)

"""## Cosine Similarity"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama produk
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['product_id'], columns=data['product_id'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap produk
cosine_sim_df.sample(10, axis=1).sample(10, axis=0)

"""## Mendapatkan Rekomendasi"""

def product_recommendations(product_id, similarity_data=cosine_sim_df,
                            items=data,
                            k=5):
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,product_id].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop nama_resto agar nama resto yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(product_id, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

cust_id = 'product_31234'

data[data.product_id.eq(cust_id)]

# Mendapatkan rekomendasi restoran yang mirip dengan KFC
product_recommendations(cust_id, k=20)

"""# Model Development dengan Collaborative Filtering

## Data Understanding
"""

# Gabungkan dataset order items, order reviews, customers, dan product
df = pd.merge(raw_order_items, raw_order_reviews, on='order_id')
df = pd.merge(df, raw_orders, on='order_id')
df = pd.merge(df, raw_cust, on='customer_id')
df = pd.merge(df, raw_products[['product_id', 'product_category_name']],
              on='product_id')
df = pd.merge(df, raw_sellers, on='seller_id')
df = pd.merge(df, rating_sold[['product_id', 'sold']], on='product_id')

df.info()

"""Menghapus beberapa kolom yang tidak berguna"""

df.drop(['order_id', 'freight_value', 'review_id','customer_id'],
        axis=1, inplace=True)

df.info()

"""## Data Preparation"""

cust_ids = df['customer_unique_id'].unique().tolist()
print('jumlah customer unik:', len(cust_ids))

# Melakukan encoding custID
user_to_user_encoded = {x: i for i, x in enumerate(cust_ids)}

# Melakukan proses encoding angka ke ke custID
user_encoded_to_user = {i: x for i, x in enumerate(cust_ids)}

product_ids = df['product_id'].unique().tolist()
print('jumlah product unik:', len(product_ids))

# Melakukan encoding productID
product_to_product_encoded = {x: i for i, x in enumerate(product_ids)}

# Melakukan proses encoding angka ke ke productID
product_encoded_to_product = {i: x for i, x in enumerate(product_ids)}

# Mapping customer unique id ke dataframe customer
df['customer'] = df['customer_unique_id'].map(user_to_user_encoded)

# Mapping product id ke dataframe product
df['product'] = df['product_id'].map(product_to_product_encoded)

# Mendapatkan jumlah user
num_customers = len(user_to_user_encoded)
print(num_customers)

# Mendapatkan jumlah produk
num_products = len(product_encoded_to_product)
print(num_products)

# Nilai minimum rating
min_rating = min(df['review_score'])

# Nilai maksimal rating
max_rating = max(df['review_score'])

print('Number of User: {}, Number of Product: {}, Min Rating: {}, Max Rating: {}'.format(
    num_customers, num_products, min_rating, max_rating
))

"""## Split Data Train dan Data Test"""

# Membuat variabel y untuk membuat rating dari hasil
y = df['review_score'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

x_train, x_val, y_train, y_val = train_test_split(df[['customer', 'product']].to_numpy(),
                                                  y,
                                                  test_size=0.2,
                                                  random_state=453)

print(x_train[:5])
print(y_train[:5])

"""## Training"""

import tensorflow as tff

class RecommenderNet(tff.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_custs, num_products, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_custs = num_custs
    self.num_products = num_products
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_custs,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_custs, 1) # layer embedding user bias
    self.product_embedding = layers.Embedding( # layer embeddings product
        num_products,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.product_bias = layers.Embedding(num_products, 1) # layer embedding product bias

  def call(self, inputs):
    cust_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    cust_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    product_vector = self.product_embedding(inputs[:, 1]) # memanggil layer embedding 3
    product_bias = self.product_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_product = tff.tensordot(cust_vector, product_vector, 2)

    x = dot_user_product + cust_bias + product_bias

    return tff.nn.sigmoid(x) # activation sigmoid

model = RecommenderNet(num_customers, num_products, 50) # inisialisasi model

# model compile
model.compile(
    loss = keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[keras.metrics.RootMeanSquaredError()]
)

hist = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 32,
    epochs = 100,
    validation_data = (x_val, y_val)
)

plt.plot(hist.history['root_mean_squared_error'])
plt.plot(hist.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""## Mendapatkan Rekomendasi"""

product_df = pd.merge(raw_products,
                      raw_order_items[['product_id',
                                       'seller_id']].drop_duplicates('product_id'),
                      on='product_id', how='left')
df2 = df

# Mengambil sample user
user_id = df2.groupby('customer_unique_id').count()
user_id = user_id[user_id['product_id'] > 5].sample(1).index[0]

# user_id = df2.customer_unique_id.sample(1).iloc[0]
product_bought_by_user = df2[df2.customer_unique_id == user_id]

product_not_bought = product_df[~product_df['product_id'].isin(product_bought_by_user.product_id.values)]['product_id']
product_not_bought = list(
    set(product_not_bought)
    .intersection(set(product_to_product_encoded.keys()))
)

product_not_bought = [[product_to_product_encoded.get(x)] for x in product_not_bought]
user_encoder = user_to_user_encoded.get(user_id)
user_product_array = np.hstack(
    ([[user_encoder]] * len(product_not_bought), product_not_bought)
)

# predict rekomendasi
ratings = model.predict(user_product_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
top_ratings_indices

recommended_product_ids = [
    product_encoded_to_product.get(product_not_bought[x][0]) for x in top_ratings_indices
]

print('\nShowing recommendations for users:\n{}'.format(user_id))
print('===' * 9)

top_product_user = (
    product_bought_by_user.drop_duplicates('product_id')
    .sort_values(
        by = 'review_score',
        ascending=False
    )
    .head(5)
    .product_id.values
)

print('\n\nProduct with high reviews from user')
product_df_rows = product_df[product_df['product_id'].isin(top_product_user)]
for row in product_df_rows.itertuples():
    print(row.product_id, ':', row.product_category_name)

print('\n\nTop 10 product recommendation')

recommended_product = product_df[product_df['product_id'].isin(recommended_product_ids)]
for i, row in enumerate(recommended_product.itertuples()):
    print(i+1, '.', row.product_id, '\t:', row.product_category_name,
          '\n   ', row.seller_id)

df2[df2['customer_unique_id'] == user_id]